{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94b36749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import redis\n",
    "r = redis.Redis(host='localhost', port=6379, db=0)\n",
    "print(r.ping())  # True means Redis is connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0653047d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nabeel\n"
     ]
    }
   ],
   "source": [
    "r.set(\"name\", \"Nabeel\")\n",
    "print(r.get(\"name\").decode(\"utf-8\"))  # Output: Nabeel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "725e0d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'11'\n",
      "b'9'\n"
     ]
    }
   ],
   "source": [
    "r.set(\"counter\", 10)\n",
    "r.incr(\"counter\")\n",
    "print(r.get(\"counter\"))  # 11\n",
    "\n",
    "r.decr(\"counter\", amount=2)\n",
    "print(r.get(\"counter\"))  # 9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d08da20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#r.delete(\"name\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d1a7577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{b'name': b'Ali', b'age': b'25'}\n"
     ]
    }
   ],
   "source": [
    "#hash\n",
    "r.hset(\"user:1\", mapping={\"name\": \"Ali\", \"age\": 25})\n",
    "print(r.hgetall(\"user:1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31e0f188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'apple', b'banana', b'cherry', b'apple', b'banana', b'cherry']\n"
     ]
    }
   ],
   "source": [
    "#list\n",
    "r.rpush(\"fruits\", \"apple\", \"banana\", \"cherry\")\n",
    "print(r.lrange(\"fruits\", 0, -1))  # all elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b683625d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{b'green', b'blue', b'red'}\n"
     ]
    }
   ],
   "source": [
    "#set\n",
    "r.sadd(\"colors\", \"red\", \"blue\", \"green\")\n",
    "print(r.smembers(\"colors\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc3922aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(b'Ali', 100.0), (b'Zara', 150.0)]\n"
     ]
    }
   ],
   "source": [
    "#Sorted Sets\n",
    "r.zadd(\"scores\", {\"Ali\": 100, \"Zara\": 150})\n",
    "print(r.zrange(\"scores\", 0, -1, withscores=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "561b72c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "#TTL\n",
    "r.set(\"temp_key\", \"data\", ex=10)  # expires after 10 seconds\n",
    "print(r.ttl(\"temp_key\"))  # shows remaining time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c82ce84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'subscribe', 'pattern': None, 'channel': b'channel1', 'data': 1}\n"
     ]
    }
   ],
   "source": [
    "#Publisher\n",
    "r.publish(\"channel1\", \"Hello Redis!\")\n",
    "\n",
    "#SUbscriber\n",
    "pubsub = r.pubsub()\n",
    "pubsub.subscribe(\"channel1\")\n",
    "\n",
    "for message in pubsub.listen():\n",
    "    print(message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c87bb1c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, 2]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transaction\n",
    "pipe = r.pipeline()\n",
    "pipe.set(\"a\", 1)\n",
    "pipe.incr(\"a\")\n",
    "pipe.execute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d100e94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True, True, b'value1']\n"
     ]
    }
   ],
   "source": [
    "#pipline batch operation\n",
    "pipe = r.pipeline()\n",
    "pipe.set(\"key1\", \"value1\")\n",
    "pipe.set(\"key2\", \"value2\")\n",
    "pipe.get(\"key1\")\n",
    "results = pipe.execute()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0bbb782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expensive Result\n"
     ]
    }
   ],
   "source": [
    "#cache\n",
    "def expensive_function():\n",
    "    return \"Expensive Result\"\n",
    "\n",
    "cache_key = \"expensive_result\"\n",
    "if not r.exists(cache_key):\n",
    "    result = expensive_function()\n",
    "    r.set(cache_key, result, ex=60)  # cache for 60 seconds\n",
    "else:\n",
    "    result = r.get(cache_key).decode()\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9544f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored session token: 23f043bc-1e10-4ff3-b33f-e60f9c71966f\n",
      "Retrieved session token: 23f043bc-1e10-4ff3-b33f-e60f9c71966f\n",
      "Session after delete: None\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "def store_user_session(user_id):\n",
    "    \"\"\"\n",
    "    Generates a unique session token (UUID) for a user and stores it in Redis.\n",
    "    The session is stored under the key pattern: user:{user_id}:session\n",
    "    \"\"\"\n",
    "    session_key = f\"user:{user_id}:session\"\n",
    "    token = str(uuid.uuid4())   # Generate a random UUID as a session token\n",
    "    r.set(session_key, token)   # Store token in Redis\n",
    "    return token\n",
    "\n",
    "def get_user_session(user_id):\n",
    "    \"\"\"\n",
    "    Retrieves the stored session token for the given user_id.\n",
    "    Returns None if the session does not exist or is expired.\n",
    "    \"\"\"\n",
    "    session_key = f\"user:{user_id}:session\"\n",
    "    token = r.get(session_key)\n",
    "    return token.decode('utf-8') if token else None\n",
    "\n",
    "def delete_user_session(user_id):\n",
    "    \"\"\"\n",
    "    Deletes the session entry from Redis for the specified user_id.\n",
    "    \"\"\"\n",
    "    session_key = f\"user:{user_id}:session\"\n",
    "    r.delete(session_key)\n",
    "\n",
    "# Usage demonstration\n",
    "session_token = store_user_session(1001)\n",
    "print(f\"Stored session token: {session_token}\")\n",
    "\n",
    "retrieved_token = get_user_session(1001)\n",
    "print(f\"Retrieved session token: {retrieved_token}\")\n",
    "\n",
    "delete_user_session(1001)\n",
    "print(f\"Session after delete: {get_user_session(1001)}\")  # Should be None or empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ef269a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'task1'\n",
      "b'task3'\n"
     ]
    }
   ],
   "source": [
    "# LPUSH: Push an element to the head (left) of the list\n",
    "r.lpush(\"task_queue\", \"task1\")\n",
    "\n",
    "# RPUSH: Push an element to the tail (right) of the list\n",
    "r.rpush(\"task_queue\", \"task2\")\n",
    "r.rpush(\"task_queue\", \"task3\")\n",
    "\n",
    "# LPOP: Pop (remove and return) the element at the head\n",
    "task = r.lpop(\"task_queue\")\n",
    "print(task)  # b'task1'\n",
    "\n",
    "# Optional: RPOP removes and returns the element at the tail\n",
    "task = r.rpop(\"task_queue\")\n",
    "print(task)  # b'task3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c47e2cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alice@example.com\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HSET: Store 'name' and 'email' fields for a user hash key\n",
    "r.hset(\"user:1001\", \"name\", \"Alice\")\n",
    "r.hset(\"user:1001\", \"email\", \"alice@example.com\")\n",
    "\n",
    "# HGET: Retrieve a single field from the hash\n",
    "email = r.hget(\"user:1001\", \"email\")\n",
    "print(email.decode('utf-8'))  # alice@example.com\n",
    "\n",
    "# HDEL: Remove a field from the hash\n",
    "r.hdel(\"user:1001\", \"email\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "380374b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Bob', 'email': 'bob@example.com'}\n"
     ]
    }
   ],
   "source": [
    "def create_user_profile(user_id, name, email):\n",
    "    \"\"\"\n",
    "    Creates a user profile in Redis under the key 'user:{user_id}'.\n",
    "    'name' and 'email' are stored as separate fields in the hash.\n",
    "    \"\"\"\n",
    "    user_key = f\"user:{user_id}\"\n",
    "    r.hset(user_key, mapping={\"name\": name, \"email\": email})\n",
    "\n",
    "def get_user_profile(user_id):\n",
    "    \"\"\"\n",
    "    Retrieves and returns all fields in the user profile hash\n",
    "    as a Python dictionary. Keys and values are decoded from bytes.\n",
    "    \"\"\"\n",
    "    user_key = f\"user:{user_id}\"\n",
    "    profile_data = r.hgetall(user_key)\n",
    "    return {k.decode('utf-8'): v.decode('utf-8') for k, v in profile_data.items()}\n",
    "\n",
    "def delete_user_profile(user_id):\n",
    "    \"\"\"\n",
    "    Deletes the entire user profile key from Redis.\n",
    "    \"\"\"\n",
    "    user_key = f\"user:{user_id}\"\n",
    "    r.delete(user_key)\n",
    "\n",
    "# Usage demonstration\n",
    "create_user_profile(1002, \"Bob\", \"bob@example.com\")\n",
    "print(get_user_profile(1002))  # e.g. {'name': 'Bob', 'email': 'bob@example.com'}\n",
    "delete_user_profile(1002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f47237b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{b'windows', b'redis', b'backend'}\n",
      "[(b'player1', 10.0), (b'player2', 20.0)]\n"
     ]
    }
   ],
   "source": [
    "# SADD: Add multiple members to a set\n",
    "r.sadd(\"tags:python\", \"redis\", \"windows\", \"backend\")\n",
    "\n",
    "# SMEMBERS: Retrieve all unique members in the set\n",
    "tags = r.smembers(\"tags:python\")\n",
    "print(tags)  # {b'redis', b'windows', b'backend'}\n",
    "\n",
    "# ZADD: Add members with scores\n",
    "r.zadd(\"leaderboard\", {\"player1\": 10, \"player2\": 20})\n",
    "\n",
    "# ZRANGE: Retrieve members in ascending order of score\n",
    "leaders = r.zrange(\"leaderboard\", 0, -1, withscores=True)\n",
    "print(leaders)  # [(b'player1', 10.0), (b'player2', 20.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a4fb44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'python', 'redis'}\n",
      "[('Alice', 300.0), ('Bob', 450.0)]\n"
     ]
    }
   ],
   "source": [
    "def add_tag(post_id, tag):\n",
    "    \"\"\"\n",
    "    Adds a 'tag' to the set of tags belonging to a specific post.\n",
    "    Each post has its own set under 'post:{post_id}:tags'.\n",
    "    \"\"\"\n",
    "    r.sadd(f\"post:{post_id}:tags\", tag)\n",
    "\n",
    "def get_tags(post_id):\n",
    "    \"\"\"\n",
    "    Retrieves all tags for a specific post, decoding the bytes into strings.\n",
    "    \"\"\"\n",
    "    raw_tags = r.smembers(f\"post:{post_id}:tags\")\n",
    "    return {tag.decode('utf-8') for tag in raw_tags}\n",
    "\n",
    "def update_leaderboard(player, score):\n",
    "    \"\"\"\n",
    "    Updates or inserts a player's score in the 'game:leaderboard' sorted set.\n",
    "    A higher score indicates a better position if sorting descending.\n",
    "    \"\"\"\n",
    "    r.zadd(\"game:leaderboard\", {player: score})\n",
    "\n",
    "def get_leaderboard():\n",
    "    \"\"\"\n",
    "    Returns an ascending list of (player, score) tuples from the leaderboard.\n",
    "    To invert the sorting (highest first), you'd use ZREVRANGE.\n",
    "    \"\"\"\n",
    "    entries = r.zrange(\"game:leaderboard\", 0, -1, withscores=True)\n",
    "    return [(player.decode('utf-8'), score) for player, score in entries]\n",
    "\n",
    "# Usage demonstration\n",
    "add_tag(123, \"python\")\n",
    "add_tag(123, \"redis\")\n",
    "print(get_tags(123))\n",
    "\n",
    "update_leaderboard(\"Alice\", 300)\n",
    "update_leaderboard(\"Bob\", 450)\n",
    "print(get_leaderboard())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f140f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting on queue: blocking_queue\n",
      "Received task: task_block_1\n",
      "Received task: task_block_2\n"
     ]
    }
   ],
   "source": [
    "def blocking_consumer(queue_name):\n",
    "    \"\"\"\n",
    "    Continuously listens to the specified queue (Redis list) using BLPOP,\n",
    "    which blocks until new items are pushed. Once an item arrives,\n",
    "    it is removed from the queue and processed.\n",
    "    \"\"\"\n",
    "    print(f\"Waiting on queue: {queue_name}\")\n",
    "    while True:\n",
    "        result = r.blpop(queue_name)\n",
    "        if result:\n",
    "            list_name, task_bytes = result\n",
    "            task = task_bytes.decode('utf-8')\n",
    "            print(f\"Received task: {task}\")\n",
    "        else:\n",
    "            print(\"Queue is empty or an error occurred.\")\n",
    "            break\n",
    "\n",
    "def enqueue_task(queue_name, task):\n",
    "    \"\"\"\n",
    "    Pushes a task to the end of a Redis list (queue).\n",
    "    \"\"\"\n",
    "    r.rpush(queue_name, task)\n",
    "\n",
    "# Example usage:\n",
    "enqueue_task(\"blocking_queue\", \"task_block_1\")\n",
    "enqueue_task(\"blocking_queue\", \"task_block_2\")\n",
    "\n",
    "# In a real application, the consumer might run in a separate thread or process\n",
    "blocking_consumer(\"blocking_queue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "879c34d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache miss. Fetching from API...\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='api.example.com', port=443): Max retries exceeded with url: /users/42 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000021AE4A06300>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mgaierror\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Ineuron-materials-FSDS\\Gen AI\\Learning-langgraph\\langgraph\\Lib\\site-packages\\urllib3\\connection.py:174\u001b[39m, in \u001b[36mHTTPConnection._new_conn\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m     conn = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mextra_kw\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Ineuron-materials-FSDS\\Gen AI\\Learning-langgraph\\langgraph\\Lib\\site-packages\\urllib3\\util\\connection.py:72\u001b[39m, in \u001b[36mcreate_connection\u001b[39m\u001b[34m(address, timeout, source_address, socket_options)\u001b[39m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m six.raise_from(\n\u001b[32m     69\u001b[39m         LocationParseError(\u001b[33mu\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, label empty or too long\u001b[39m\u001b[33m\"\u001b[39m % host), \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     70\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43msocket\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msocket\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSOCK_STREAM\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m     73\u001b[39m     af, socktype, proto, canonname, sa = res\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Ineuron-materials-FSDS\\Gen AI\\Learning-langgraph\\langgraph\\Lib\\socket.py:978\u001b[39m, in \u001b[36mgetaddrinfo\u001b[39m\u001b[34m(host, port, family, type, proto, flags)\u001b[39m\n\u001b[32m    977\u001b[39m addrlist = []\n\u001b[32m--> \u001b[39m\u001b[32m978\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_socket\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    979\u001b[39m     af, socktype, proto, canonname, sa = res\n",
      "\u001b[31mgaierror\u001b[39m: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mNewConnectionError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Ineuron-materials-FSDS\\Gen AI\\Learning-langgraph\\langgraph\\Lib\\site-packages\\urllib3\\connectionpool.py:716\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[39m\n\u001b[32m    715\u001b[39m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m716\u001b[39m httplib_response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    717\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    718\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    719\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    721\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    722\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    723\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    724\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    726\u001b[39m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[32m    727\u001b[39m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[32m    728\u001b[39m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[32m    729\u001b[39m \u001b[38;5;66;03m# mess.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Ineuron-materials-FSDS\\Gen AI\\Learning-langgraph\\langgraph\\Lib\\site-packages\\urllib3\\connectionpool.py:404\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[39m\n\u001b[32m    403\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m404\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    406\u001b[39m     \u001b[38;5;66;03m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Ineuron-materials-FSDS\\Gen AI\\Learning-langgraph\\langgraph\\Lib\\site-packages\\urllib3\\connectionpool.py:1061\u001b[39m, in \u001b[36mHTTPSConnectionPool._validate_conn\u001b[39m\u001b[34m(self, conn)\u001b[39m\n\u001b[32m   1060\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(conn, \u001b[33m\"\u001b[39m\u001b[33msock\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1061\u001b[39m     \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1063\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn.is_verified:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Ineuron-materials-FSDS\\Gen AI\\Learning-langgraph\\langgraph\\Lib\\site-packages\\urllib3\\connection.py:363\u001b[39m, in \u001b[36mHTTPSConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    362\u001b[39m     \u001b[38;5;66;03m# Add certificate verification\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m     \u001b[38;5;28mself\u001b[39m.sock = conn = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    364\u001b[39m     hostname = \u001b[38;5;28mself\u001b[39m.host\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Ineuron-materials-FSDS\\Gen AI\\Learning-langgraph\\langgraph\\Lib\\site-packages\\urllib3\\connection.py:186\u001b[39m, in \u001b[36mHTTPConnection._new_conn\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SocketError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[32m    187\u001b[39m         \u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m % e\n\u001b[32m    188\u001b[39m     )\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m conn\n",
      "\u001b[31mNewConnectionError\u001b[39m: <urllib3.connection.HTTPSConnection object at 0x0000021AE4A06300>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mMaxRetryError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Ineuron-materials-FSDS\\Gen AI\\Learning-langgraph\\langgraph\\Lib\\site-packages\\requests\\adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Ineuron-materials-FSDS\\Gen AI\\Learning-langgraph\\langgraph\\Lib\\site-packages\\urllib3\\connectionpool.py:802\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[39m\n\u001b[32m    800\u001b[39m     e = ProtocolError(\u001b[33m\"\u001b[39m\u001b[33mConnection aborted.\u001b[39m\u001b[33m\"\u001b[39m, e)\n\u001b[32m--> \u001b[39m\u001b[32m802\u001b[39m retries = \u001b[43mretries\u001b[49m\u001b[43m.\u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    803\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m=\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m=\u001b[49m\u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    804\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    805\u001b[39m retries.sleep()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Ineuron-materials-FSDS\\Gen AI\\Learning-langgraph\\langgraph\\Lib\\site-packages\\urllib3\\util\\retry.py:594\u001b[39m, in \u001b[36mRetry.increment\u001b[39m\u001b[34m(self, method, url, response, error, _pool, _stacktrace)\u001b[39m\n\u001b[32m    593\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m new_retry.is_exhausted():\n\u001b[32m--> \u001b[39m\u001b[32m594\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause))\n\u001b[32m    596\u001b[39m log.debug(\u001b[33m\"\u001b[39m\u001b[33mIncremented Retry for (url=\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m, url, new_retry)\n",
      "\u001b[31mMaxRetryError\u001b[39m: HTTPSConnectionPool(host='api.example.com', port=443): Max retries exceeded with url: /users/42 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000021AE4A06300>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mConnectionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     24\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m user_info\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Usage\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m user = \u001b[43mget_user_data\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# First call => cache miss\u001b[39;00m\n\u001b[32m     28\u001b[39m user_again = get_user_data(\u001b[32m42\u001b[39m)  \u001b[38;5;66;03m# Subsequent call => cache hit\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mget_user_data\u001b[39m\u001b[34m(user_id)\u001b[39m\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m json.loads(cached_data)\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCache miss. Fetching from API...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhttps://api.example.com/users/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43muser_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m user_info = response.json()\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Store in Redis for 60 seconds\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Ineuron-materials-FSDS\\Gen AI\\Learning-langgraph\\langgraph\\Lib\\site-packages\\requests\\api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(url, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Ineuron-materials-FSDS\\Gen AI\\Learning-langgraph\\langgraph\\Lib\\site-packages\\requests\\api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Ineuron-materials-FSDS\\Gen AI\\Learning-langgraph\\langgraph\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Ineuron-materials-FSDS\\Gen AI\\Learning-langgraph\\langgraph\\Lib\\site-packages\\requests\\sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Ineuron-materials-FSDS\\Gen AI\\Learning-langgraph\\langgraph\\Lib\\site-packages\\requests\\adapters.py:700\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    696\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e.reason, _SSLError):\n\u001b[32m    697\u001b[39m         \u001b[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[32m    698\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request=request)\n\u001b[32m--> \u001b[39m\u001b[32m700\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request=request)\n\u001b[32m    702\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    703\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request=request)\n",
      "\u001b[31mConnectionError\u001b[39m: HTTPSConnectionPool(host='api.example.com', port=443): Max retries exceeded with url: /users/42 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000021AE4A06300>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))"
     ]
    }
   ],
   "source": [
    "#caching\n",
    "import requests\n",
    "import json\n",
    "import redis\n",
    "\n",
    "def get_user_data(user_id):\n",
    "    \"\"\"\n",
    "    Retrieves user data from a hypothetical API endpoint.\n",
    "    If the data is found in Redis (cache), use that. Otherwise, call the API,\n",
    "    store the response in Redis with a 60-second expiration, and return it.\n",
    "    \"\"\"\n",
    "    cache_key = f\"user_data:{user_id}\"\n",
    "    cached_data = r.get(cache_key)\n",
    "    if cached_data:\n",
    "        print(\"Cache hit!\")\n",
    "        return json.loads(cached_data)\n",
    "\n",
    "    print(\"Cache miss. Fetching from API...\")\n",
    "    response = requests.get(f\"https://api.example.com/users/{user_id}\")\n",
    "    user_info = response.json()\n",
    "\n",
    "    # Store in Redis for 60 seconds\n",
    "    r.setex(cache_key, 60, json.dumps(user_info))\n",
    "    return user_info\n",
    "\n",
    "# Usage\n",
    "user = get_user_data(42)  # First call => cache miss\n",
    "user_again = get_user_data(42)  # Subsequent call => cache hit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "468a9cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved token: session_token_abc\n"
     ]
    }
   ],
   "source": [
    "def store_session_with_expiry(user_id, token, ttl=3600):\n",
    "    \"\"\"\n",
    "    Stores a session token for a specific user with a time-to-live (TTL).\n",
    "    By default, the session expires after 1 hour (3600 seconds).\n",
    "    \"\"\"\n",
    "    session_key = f\"user:{user_id}:session\"\n",
    "    r.setex(session_key, ttl, token)\n",
    "\n",
    "def get_session_with_expiry(user_id):\n",
    "    \"\"\"\n",
    "    Retrieves the session token for the user. Returns None if the key doesn't exist\n",
    "    or if it has expired.\n",
    "    \"\"\"\n",
    "    session_key = f\"user:{user_id}:session\"\n",
    "    token = r.get(session_key)\n",
    "    return token.decode('utf-8') if token else None\n",
    "\n",
    "# Usage\n",
    "store_session_with_expiry(2001, \"session_token_abc\", 3600)\n",
    "retrieved_token = get_session_with_expiry(2001)\n",
    "print(f\"Retrieved token: {retrieved_token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12fb021d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.datacamp.com/tutorial/python-redis-beginner-guide\n",
    "#https://realpython.com/python-redis/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ff1cdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
